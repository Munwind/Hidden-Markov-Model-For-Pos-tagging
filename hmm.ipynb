{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n",
    "import math\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset= 'universal'))\n",
    "print(len(nltk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(nltk_data, train_size= 0.8, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80310\n",
      "20366\n",
      "['drink', 'NOUN']\n",
      "10164\n"
     ]
    }
   ],
   "source": [
    "train_words = []\n",
    "for doc in train_set:\n",
    "    for word, tag in doc:\n",
    "        train_words.append([word.lower(), tag])\n",
    "\n",
    "test_words = [word.lower() for doc in test_set for word, tag in doc]\n",
    "print(len(train_words))\n",
    "print(len(test_words))\n",
    "print(train_words[0])\n",
    "\n",
    "vocab = set(word[0] for word in train_words)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN', 'ADJ', 'VERB', 'ADP', 'NUM', 'CONJ', 'PRT', 'PRON', 'ADV', 'DET', '.', 'X'}\n",
      "{'NOUN': 22966, 'ADJ': 5150, 'VERB': 10860, 'ADP': 7902, 'NUM': 2801, 'CONJ': 1822, 'PRT': 2555, 'PRON': 2195, 'ADV': 2578, 'DET': 6957, '.': 9321, 'X': 5203}\n",
      "80310\n",
      "10164\n",
      "{'prolonged': {'ADJ': 0, 'DET': 0, 'CONJ': 0, '.': 0, 'NOUN': 0, 'PRT': 0, 'ADP': 0, 'VERB': 2, 'NUM': 0, 'ADV': 0, 'X': 0, 'PRON': 0}, 'fled': {'ADJ': 0, 'DET': 0, 'CONJ': 0, '.': 0, 'NOUN': 0, 'PRT': 0, 'ADP': 0, 'VERB': 1, 'NUM': 0, 'ADV': 0, 'X': 0, 'PRON': 0}, 'santa': {'ADJ': 0, 'DET': 0, 'CONJ': 0, '.': 0, 'NOUN': 2, 'PRT': 0, 'ADP': 0, 'VERB': 0, 'NUM': 0, 'ADV': 0, 'X': 0, 'PRON': 0}}\n",
      "{'ADJ': 0, 'DET': 93, 'CONJ': 0, '.': 0, 'NOUN': 0, 'PRT': 0, 'ADP': 0, 'VERB': 0, 'NUM': 0, 'ADV': 3, 'X': 0, 'PRON': 0}\n"
     ]
    }
   ],
   "source": [
    "# Precalculate the number of words in each tag\n",
    "tag_sets = set(tag for doc in train_set for word, tag in doc)\n",
    "print(tag_sets)\n",
    "store_tags = {}   # Store the numbers of word in each tag\n",
    "store_words = {}    # Store the numbers of words exist in the train set\n",
    "\n",
    "for tag in tag_sets:\n",
    "    s = 0\n",
    "    for doc in train_set:\n",
    "        for word, check_tag in doc:\n",
    "            if tag == check_tag:\n",
    "                s += 1\n",
    "    store_tags[tag] = s\n",
    "\n",
    "print(store_tags)\n",
    "print(sum(store_tags.values()))\n",
    "\n",
    "for word in vocab:\n",
    "    store_words[word] = {\n",
    "        'ADJ': 0, 'DET': 0, 'CONJ': 0, '.': 0, \n",
    "        'NOUN': 0, 'PRT': 0, 'ADP': 0, 'VERB': 0, \n",
    "        'NUM': 0, 'ADV': 0, 'X': 0, 'PRON': 0\n",
    "    }\n",
    "\n",
    "for word in train_words:\n",
    "    store_words[word[0]][word[1]] += 1\n",
    "\n",
    "print(len(store_words))\n",
    "first_three = dict(islice(store_words.items(), 3))\n",
    "print(first_three)\n",
    "print(store_words['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(classification, tag): # deal with the unknown words by \n",
    "    alpha = 0.35\n",
    "    if classification == \"UNKNOWN_CAPITAL\":\n",
    "        if tag == 'NOUN':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_ING\":\n",
    "        if tag == 'VERB':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_ED\":\n",
    "        if tag == 'VERB':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_LY\":\n",
    "        if tag == 'ADV':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_HYPHEN\":\n",
    "        if tag == 'ADJ':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_NUMBER\":\n",
    "        if tag == 'NOUN':\n",
    "            return alpha\n",
    "        else:\n",
    "            return (1 - alpha) / len(tag_sets)\n",
    "    elif classification == \"UNKNOWN_SHORT\":\n",
    "        if tag == 'PRT' or tag == 'CONJ':\n",
    "            return alpha / 2\n",
    "        else:\n",
    "            return (1 - alpha) / (len(tag_sets) - 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00875206827484107\n"
     ]
    }
   ],
   "source": [
    "# From words and tags => return probability\n",
    "def emission_prob(word, tag):\n",
    "    if (word.lower() not in store_words):\n",
    "        if word[0].isupper():\n",
    "            return P(\"UNKNOWN_CAPITAL\", tag)  # Capitalized word (proper noun)\n",
    "        elif word.endswith(\"ing\"):\n",
    "            return P(\"UNKNOWN_ING\", tag)  # Word ends with -ing (verb)\n",
    "        elif word.endswith(\"ed\"):\n",
    "            return P(\"UNKNOWN_ED\", tag)  # Word ends with -ed (past tense verb)\n",
    "        elif word.endswith(\"ly\"):\n",
    "            return P(\"UNKNOWN_LY\", tag)  # Word ends with -ly (adverb)\n",
    "        elif \"-\" in word:\n",
    "            return P(\"UNKNOWN_HYPHEN\", tag)  # Hyphenated word (compound)\n",
    "        elif any(char.isdigit() for char in word):\n",
    "            return P(\"UNKNOWN_NUMBER\", tag)  # Word contains digits (number or date)\n",
    "        elif len(word) <= 2:\n",
    "            return P(\"UNKNOWN_SHORT\", tag)\n",
    "        return store_tags[tag] / len(train_words)\n",
    "    return store_words[word.lower()][tag] / store_tags[tag]\n",
    "print(emission_prob('company', 'NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': 0.2884062599808368, 'ADJ': 0.042159054615138934, 'VERB': 0.01085915043117215, 'ADP': 0.13318428617055253, 'NUM': 0.00830405621207282, 'CONJ': 0.053018205046311086, 'PRT': 0.0015969338869370809, 'PRON': 0.07824976045991695, 'ADV': 0.05269881826892367, 'DET': 0.2312360268284893, '.': 0.07920792079207921, 'X': 0.021079527307569467}\n",
      "{'NOUN': 0.004471414883423826, 'ADJ': 0.0, 'VERB': 0.0, 'ADP': 0.0009581603321622484, 'NUM': 0.0006387735547748323, 'CONJ': 0.0, 'PRT': 0.0, 'PRON': 0.0, 'ADV': 0.00031938677738741617, 'DET': 0.00031938677738741617, '.': 0.9929734908974769, 'X': 0.00031938677738741617}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the start and end state probabilities with each tag\n",
    "store_start = {}\n",
    "store_end = {}\n",
    "\n",
    "for tag in tag_sets:\n",
    "    store_start[tag] = 0\n",
    "    store_end[tag] = 0\n",
    "\n",
    "for tag in tag_sets:\n",
    "    s0, s1 = 0, 0\n",
    "    for doc in train_set:\n",
    "        if doc[0][1] == tag:\n",
    "            s0 += 1\n",
    "        if doc[-1][1] == tag:\n",
    "            s1 += 1\n",
    "    store_start[tag] = s0 / len(train_set)\n",
    "    store_end[tag] = s1 / len(train_set)\n",
    "    \n",
    "print(store_start)\n",
    "print(store_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculate tag2 given tag1\n",
    "def transition_prob(tag2, tag1):\n",
    "    cnt = 0\n",
    "    for doc in train_set:\n",
    "        for i in range(1, len(doc)):\n",
    "            if doc[i - 1][1] == tag1 and doc[i][1] == tag2:\n",
    "                cnt += 1\n",
    "    return cnt / store_tags[tag1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the transition table \n",
    "tags_matrix = np.zeros((len(tag_sets), len(tag_sets)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tag_sets)):\n",
    "    for j, t2 in enumerate(list(tag_sets)):\n",
    "        tags_matrix[i][j] = transition_prob(t2, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADP</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADV</th>\n",
       "      <th>DET</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.262170</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.149134</td>\n",
       "      <td>0.176740</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.042411</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.240007</td>\n",
       "      <td>0.028825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>0.021748</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.020971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.092357</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.035543</td>\n",
       "      <td>0.083886</td>\n",
       "      <td>0.133610</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>0.215930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.323462</td>\n",
       "      <td>0.107062</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.320931</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>0.034548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.351303</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>0.184220</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.118886</td>\n",
       "      <td>0.202428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.150384</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.060373</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.009330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.082975</td>\n",
       "      <td>0.401174</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.012133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.212756</td>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.484738</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.041913</td>\n",
       "      <td>0.088383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.339022</td>\n",
       "      <td>0.119472</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.070985</td>\n",
       "      <td>0.139255</td>\n",
       "      <td>0.022886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.635906</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.045134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.122412</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>0.048385</td>\n",
       "      <td>0.075421</td>\n",
       "      <td>0.042485</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.095161</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.018560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.185086</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.056698</td>\n",
       "      <td>0.160869</td>\n",
       "      <td>0.075726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NOUN       ADJ      VERB       ADP       NUM      CONJ       PRT  \\\n",
       "NOUN  0.262170  0.012540  0.149134  0.176740  0.009144  0.042411  0.043935   \n",
       "ADJ   0.696893  0.063301  0.011456  0.080583  0.021748  0.016893  0.011456   \n",
       "VERB  0.110589  0.066390  0.167956  0.092357  0.022836  0.005433  0.030663   \n",
       "ADP   0.323462  0.107062  0.008479  0.016958  0.063275  0.000886  0.001266   \n",
       "NUM   0.351303  0.035345  0.020707  0.037487  0.184220  0.014281  0.026062   \n",
       "CONJ  0.349067  0.113611  0.150384  0.055982  0.040615  0.000549  0.004391   \n",
       "PRT   0.250489  0.082975  0.401174  0.019569  0.056751  0.002348  0.001174   \n",
       "PRON  0.212756  0.070615  0.484738  0.022323  0.006834  0.005011  0.014123   \n",
       "ADV   0.032196  0.130721  0.339022  0.119472  0.029868  0.006982  0.014740   \n",
       "DET   0.635906  0.206411  0.040247  0.009918  0.022855  0.000431  0.000287   \n",
       ".     0.122412  0.032078  0.086042  0.048385  0.075421  0.042485  0.002253   \n",
       "X     0.061695  0.017682  0.206419  0.142226  0.003075  0.010379  0.185086   \n",
       "\n",
       "          PRON       ADV       DET         .         X  \n",
       "NOUN  0.004616  0.016895  0.012976  0.240007  0.028825  \n",
       "ADJ   0.000194  0.005243  0.005243  0.066019  0.020971  \n",
       "VERB  0.035543  0.083886  0.133610  0.034807  0.215930  \n",
       "ADP   0.069476  0.014553  0.320931  0.038724  0.034548  \n",
       "NUM   0.001428  0.003570  0.003570  0.118886  0.202428  \n",
       "CONJ  0.060373  0.057080  0.123491  0.035126  0.009330  \n",
       "PRT   0.017613  0.009393  0.101370  0.045010  0.012133  \n",
       "PRON  0.006834  0.036902  0.009567  0.041913  0.088383  \n",
       "ADV   0.012025  0.081458  0.070985  0.139255  0.022886  \n",
       "DET   0.003306  0.012074  0.005893  0.017393  0.045134  \n",
       ".     0.042699  0.034868  0.095161  0.066087  0.018560  \n",
       "X     0.054200  0.025754  0.056698  0.160869  0.075726  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns= list(tag_sets), index= list(tag_sets))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26217017 0.012540277\n"
     ]
    }
   ],
   "source": [
    "print(tags_matrix[0][0], tags_matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best path is  ['PRON', 'VERB', 'ADV', 'VERB', 'PRON', '.']\n"
     ]
    }
   ],
   "source": [
    "def Viterbi(consider_string):\n",
    "    word = consider_string.split()\n",
    "    for i in range(len(word)):\n",
    "        word[i] = word[i]\n",
    "        \n",
    "    n = len(word)\n",
    "    m = len(tag_sets)\n",
    "    \n",
    "    dp = [[0] * m for _ in range(n)]    # Get the max probability\n",
    "    preBestPath = [[] for _ in range(m)]    # Get the path of all best possibilities\n",
    "    bestPath = [[] for _ in range(m)]  \n",
    "    \n",
    "    list_tag_sets = list(tag_sets)\n",
    "    \n",
    "    # Initialize the start probabilities\n",
    "    for i in range(m):\n",
    "        dp[0][i] = store_start[list_tag_sets[i]] * emission_prob(word[0], list_tag_sets[i]) * 64\n",
    "        bestPath[i].append(list_tag_sets[i])\n",
    "    \n",
    "    # Dynamic programming loop\n",
    "    for i in range(1, n):\n",
    "        for j in range(m):\n",
    "            chosenPath = []  # the best node can be chosen \n",
    "            for k in range(m):\n",
    "                # Calculate the new potential value\n",
    "                newVal = dp[i - 1][k] * emission_prob(word[i], list_tag_sets[j]) * tags_matrix[k][j] * 512\n",
    "                \n",
    "                # Update dp[i][j] with the max probability and corresponding path\n",
    "                if len(chosenPath) == 0 or newVal > dp[i][j]:\n",
    "                    dp[i][j] = newVal\n",
    "                    chosenPath = bestPath[k][:]  # Copy the best path to avoid modifying the original\n",
    "                \n",
    "            # Update the path for the current state\n",
    "            preBestPath[j] = chosenPath\n",
    "            preBestPath[j].append(list_tag_sets[j])\n",
    "        \n",
    "        # After updating paths for the current word, set bestPath = preBestPath for the next word\n",
    "        bestPath = [path[:] for path in preBestPath]  \n",
    "    \n",
    "    # Solve for the end state\n",
    "    for i in range(m):\n",
    "        dp[n - 1][i] *= store_end[list_tag_sets[i]] * 8\n",
    "        \n",
    "    # for i in range(m):\n",
    "    #     print(bestPath[i], dp[n - 1][i])\n",
    "\n",
    "    lastDp = dp[-1]\n",
    "    #print(\"probability = \", max(lastDp))\n",
    "    \n",
    "    return bestPath[lastDp.index(max(lastDp))]\n",
    "\n",
    "val = Viterbi(\"i will never forget you .\")\n",
    "print('The best path is ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  1.7086594104766846\n",
      "Number of incorrect words :  1076\n",
      "Number of unknown incorrect words :  464\n",
      "Number of unknown correct words :  851\n",
      "Viterbi Algorithm Accuracy:  94.71668467052932\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the test\n",
    "test_data = []\n",
    "used_for_test = test_set\n",
    "correct_seq = []\n",
    "total_words = 0\n",
    "\n",
    "for doc in used_for_test:\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for word, tag in doc:\n",
    "        temp.append(word.lower())\n",
    "        temp2.append(tag)\n",
    "        total_words += 1\n",
    "    test_data.append(temp)\n",
    "    correct_seq.append(temp2)\n",
    "\n",
    "#print(correct_seq)\n",
    "#print(test_data)\n",
    "check_seq = []\n",
    "start = time.time()\n",
    "for doc in test_data:\n",
    "    tagged_seq = Viterbi(' '.join(doc))\n",
    "    check_seq.append(tagged_seq)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    " \n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "cnt = 0\n",
    "\n",
    "incorrect_words = 0\n",
    "unknown_incorrect_words, unknown_correct_words = 0, 0\n",
    "\n",
    "for i in range(len(check_seq)):\n",
    "    for j in range(len(check_seq[i])):\n",
    "        if check_seq[i][j] == correct_seq[i][j]:\n",
    "            if test_data[i][j] not in store_words:\n",
    "                unknown_correct_words += 1\n",
    "            cnt += 1\n",
    "        else:\n",
    "            incorrect_words += 1\n",
    "            if test_data[i][j] not in store_words:\n",
    "                unknown_incorrect_words += 1\n",
    "            \n",
    "accuracy = cnt / total_words\n",
    "print('Number of incorrect words : ', incorrect_words)\n",
    "print('Number of unknown incorrect words : ', unknown_incorrect_words)\n",
    "print('Number of unknown correct words : ', unknown_correct_words)\n",
    "# The accuracy after adding start and end state is 94%, without that is 91%\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
